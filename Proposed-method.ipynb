{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement our proposed method --- multitasks framework\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import deepchem as dc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train dataset and test dataset\n",
    "train_dataset_file = \"train_dataset.csv\"\n",
    "test_dataset_file = \"test_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the list of all GPCR names in input file\n",
    "df = pd.read_csv('Input_Pos10Neg10.csv')\n",
    "df1 = df.drop(['ChEMBL_ID', 'Smiles'], axis = 1) \n",
    "GPCR_tasks=list(df1.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dc.data.CSVLoader(tasks=GPCR_tasks, smiles_field=\"Smiles\", featurizer=dc.feat.CircularFingerprint(size=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from train_dataset.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "TIMING: featurizing shard 0 took 15.640 s\n",
      "TIMING: dataset construction took 15.943 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "#feature enginnering, convert each ligand (in train set)into 1024 dimensional vector using ECFP4 method\n",
    "train_dataset = loader.featurize(train_dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from test_dataset.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "TIMING: featurizing shard 0 took 3.820 s\n",
      "TIMING: dataset construction took 3.916 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "#feature enginnering, convert each ligand (in test set)into 1024 dimensional vector using ECFP4 method\n",
    "test_dataset = loader.featurize(test_dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tasks = len(GPCR_tasks) ##25 tasks (GPCRS)\n",
    "n_features = train_dataset.get_data_shape()[0] ##1024 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dc.models.MultitaskClassifier(n_tasks, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001489030562100067"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the true value in test set\n",
    "y_true = test_dataset.y\n",
    "#get the prediction value from the multitask framework\n",
    "y_pred = model.predict(test_dataset)\n",
    "#using ROC score to evaluate the prediction\n",
    "metric = dc.metrics.roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5ht1d_rat 0.9973208884279665\n",
      "ackr3_human 0.9943216274326039\n",
      "ccr1_human 0.9897499184073107\n",
      "ccr1_mouse 0.9815375302663438\n",
      "ccr2_human 0.978529403934723\n",
      "ccr2_mouse 0.9474604622871046\n",
      "ccr3_human 0.9923931784346409\n",
      "ccr3_mouse 0.9995166163141995\n",
      "ccr3_rat 0.9996980676328502\n",
      "ccr4_human 0.9940026487157847\n",
      "ccr5_human 0.9765016457572206\n",
      "ccr5_mouse 0.9790655339805825\n",
      "ccr6_human 0.9608088478520372\n",
      "ccr8_human 1.0\n",
      "ccr9_human 1.0\n",
      "ccrl2_human 0.9998686974789917\n",
      "cx3c1_human 0.9997493824066449\n",
      "cxcr1_human 0.9858170357200582\n",
      "cxcr2_human 0.9971567506577665\n",
      "cxcr3_human 0.9964376876876877\n",
      "cxcr3_mouse 0.9940837378640777\n",
      "cxcr3_rat 0.9963811821471653\n",
      "cxcr4_human 0.9986660879323304\n",
      "cxcr5_human 0.9992920711974109\n",
      "q9jly8_rat 0.9978394261515858\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_tasks):\n",
    "    score = metric(dc.metrics.to_one_hot(y_true[:,i]), y_pred[:,i])\n",
    "    print(GPCR_tasks[i], score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ablation study, change the size of hidden layer\n",
    "def optimize_layers(layer1, layer2):\n",
    "    score_comb = []\n",
    "    mod = dc.models.MultitaskClassifier(n_tasks, n_features, layer_sizes = [layer1, layer2])\n",
    "    mod.fit(train_dataset)\n",
    "    y_pred_mod = mod.predict(test_dataset)\n",
    "    for i in range(n_tasks):\n",
    "        score = metric(dc.metrics.to_one_hot(y_true[:,i]), y_pred_mod[:,i])\n",
    "        score_comb.append(score)\n",
    "    return score_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = np.round(optimize_layers(1000,50),4)\n",
    "score2 = np.round(optimize_layers(1000,100),4)\n",
    "score3 = np.round(optimize_layers(1000,150),4)\n",
    "score4 = np.round(optimize_layers(2000,50),4)\n",
    "score5 = np.round(optimize_layers(2000,100),4)\n",
    "score6 = np.round(optimize_layers(2000,150),4)\n",
    "score7 = np.round(optimize_layers(3000,50),4)\n",
    "score8 = np.round(optimize_layers(3000,100),4)\n",
    "score9 = np.round(optimize_layers(3000,150),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "##summarize the prediction results using different layer size in multitasks framework\n",
    "result = pd.DataFrame(np.vstack((score1,score2,score3,score4,score5,score6,score7,score8,score9)))\n",
    "result = result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8719</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.9259</td>\n",
       "      <td>0.9812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9330</td>\n",
       "      <td>0.9843</td>\n",
       "      <td>0.9194</td>\n",
       "      <td>0.9454</td>\n",
       "      <td>0.9788</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>0.8915</td>\n",
       "      <td>0.9769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9819</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.9887</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.9430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>0.9941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>0.9595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9367</td>\n",
       "      <td>0.9707</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>0.9714</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.9675</td>\n",
       "      <td>0.9611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>0.9903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>0.9886</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>0.9930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9819</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.9903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9882</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>0.9878</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>0.9804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>0.8855</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>0.9426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9272</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.9560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.9543</td>\n",
       "      <td>0.9314</td>\n",
       "      <td>0.9184</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.9487</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.8879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.9999</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9780</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9194</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.9789</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>0.9426</td>\n",
       "      <td>0.9631</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.9847</td>\n",
       "      <td>0.9646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.9932</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>0.9949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.9827</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.9968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>0.8943</td>\n",
       "      <td>0.9798</td>\n",
       "      <td>0.9621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.9967</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>0.9644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.9918</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.9964</td>\n",
       "      <td>0.9918</td>\n",
       "      <td>0.9918</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.9971</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.9903</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>0.8967</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.9957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8\n",
       "0   0.8719  0.9488  0.8976  0.9588  0.9500  0.9652  0.6936  0.9259  0.9812\n",
       "1   0.9330  0.9843  0.9194  0.9454  0.9788  0.9768  0.8401  0.8915  0.9769\n",
       "2   0.9819  0.9841  0.9887  0.9673  0.9877  0.9858  0.8392  0.9679  0.9430\n",
       "3   0.9848  0.9870  0.9896  0.9896  0.9961  0.9782  0.9331  0.9651  0.9941\n",
       "4   0.9633  0.9392  0.9555  0.9572  0.9500  0.9647  0.9372  0.9729  0.9595\n",
       "5   0.9367  0.9707  0.9668  0.9569  0.9714  0.9752  0.9050  0.9675  0.9611\n",
       "6   0.9855  0.9811  0.9893  0.9915  0.9879  0.9909  0.9725  0.9839  0.9903\n",
       "7   0.9977  0.9994  0.9961  0.9886  0.9954  0.9981  0.9836  0.9917  0.9930\n",
       "8   0.9995  0.9997  0.9997  1.0000  0.9997  0.9998  0.9819  0.9997  0.9903\n",
       "9   0.9882  0.9879  0.9878  0.9467  0.9583  0.9895  0.9475  0.9873  0.9804\n",
       "10  0.9480  0.9560  0.9582  0.9537  0.9615  0.9729  0.8855  0.9570  0.9426\n",
       "11  0.9825  0.9639  0.9765  0.9313  0.9739  0.9652  0.9272  0.9645  0.9560\n",
       "12  0.9505  0.9543  0.9314  0.9184  0.9198  0.9487  0.9656  0.9443  0.8879\n",
       "13  0.9999  1.0000  1.0000  0.9997  1.0000  0.9999  0.9780  1.0000  0.9993\n",
       "14  1.0000  1.0000  1.0000  0.9999  1.0000  1.0000  0.9194  0.9952  0.9995\n",
       "15  0.9998  0.9999  1.0000  0.9997  0.9999  0.9999  0.9808  0.9998  1.0000\n",
       "16  0.9997  0.9995  0.9996  0.9997  0.9997  0.9997  0.9990  0.9993  0.9995\n",
       "17  0.9789  0.9759  0.9782  0.9426  0.9631  0.9760  0.9742  0.9847  0.9646\n",
       "18  0.9949  0.9954  0.9932  0.9896  0.9877  0.9964  0.9838  0.9912  0.9949\n",
       "19  0.9959  0.9974  0.9959  0.9875  0.9966  0.9978  0.9827  0.9967  0.9968\n",
       "20  0.9744  0.9745  0.9838  0.9828  0.9858  0.9849  0.8943  0.9798  0.9621\n",
       "21  0.9967  0.9946  0.9949  0.9683  0.9940  0.9952  0.8676  0.9922  0.9644\n",
       "22  0.9988  0.9984  0.9988  0.9950  0.9962  0.9984  0.9918  0.9979  0.9976\n",
       "23  0.9964  0.9918  0.9918  0.9808  0.9702  0.9935  0.9951  0.9755  0.9711\n",
       "24  0.9971  0.9971  0.9973  0.9903  0.9980  0.9974  0.8967  0.9966  0.9957"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result = result.rename(columns = {0:\"GPCR\", 1:\"(1000,50)\", 2:\"(1000,100)\", 3:\"(1000,150)\", 4:\"(2000,50)\", 5:\"(2000,100)\", 6:\"(2000,150)\", 7:\"(3000,50)\", 8:\"(3000,100)\", 9:\"(3000,150)\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.978240\n",
       "1    0.983236\n",
       "2    0.979604\n",
       "3    0.973652\n",
       "4    0.980868\n",
       "5    0.986004\n",
       "6    0.931016\n",
       "7    0.977124\n",
       "8    0.976072\n",
       "dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the mean AUC value of multitasks frame with diffent layer size\n",
    "result.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.9882\n",
       "1    0.9879\n",
       "2    0.9896\n",
       "3    0.9828\n",
       "4    0.9877\n",
       "5    0.9909\n",
       "6    0.9475\n",
       "7    0.9847\n",
       "8    0.9812\n",
       "dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the median AUC value of multitasks frame with diffent layer size\n",
    "result.median(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
